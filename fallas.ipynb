{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de fallas \n",
    "\n",
    "En este cuadernillo utilizaremos un dataset sintético que simula un equipo industrial. Más precisamente el dataset tiene lecturas de sensor de esta máquina simulada. El dataset fue publicado en la [Conferencia de IA para industrias 2020](https://ieeexplore.ieee.org/document/9253083) y fue obtenido del [repositorio UCI](https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset)\n",
    "\n",
    "Primero exploraremos el dataset, luego entrenaremos un modelo predictivo y finalmente analizaremos los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los datos\n",
    "\n",
    "El dataset se distribuye en formato `csv`. Podemos trabajar  con este tipo de tablas [en Python utilizando la librería pandas](https://phuijse.github.io/PythonBook/contents/pandas/part2.html) como se muestra a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/predictive_maintenance.csv\", index_col=0).drop([\"Product ID\", \"Target\"], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas retorna un objeto de tipo `DataFrame` el cual tiene métodos y atributos muy útiles para hacer exploración. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la tabla notamos que hay dos columnas categóricas, una es el tipo de la máquina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la segunda es el tipo de falla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Failure Type'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe un importante desbalance en los tipos de falla. Como es de esperarse, la información más abundante corresponde a la máquina en operación normal (`No Failure`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación si visualiza el coeficiente de correlación entre los atributos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La temperatura ambiente y de la máquina tienen alta correlación\n",
    "- El torque y la velocidad rotacional están anti correlacionados\n",
    "\n",
    "\n",
    "A continuación se realiza [una gráfica de dispersión con matplotlib](https://phuijse.github.io/PythonBook/contents/visualization/matplotlib1.html) de las columnas Torque y velocidad rotacional, donde se colorea según el tipo de falla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6), tight_layout=True)\n",
    "\n",
    "for failure in df['Failure Type'].unique():\n",
    "    mask = df['Failure Type'] == failure\n",
    "    ax.scatter(df[\"Torque [Nm]\"].loc[mask], \n",
    "               df[\"Rotational speed [rpm]\"].loc[mask],\n",
    "               label=failure, s=10, alpha=0.25)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Torque')\n",
    "ax.set_ylabel('Velocidad rotacional');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Esta gráfica nos indica que estos dos atributos son bastante relevantes para clasificar entre falla y no falla\n",
    "\n",
    "A continuación preparemos los datos para entrenar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar un modelo de clasificación necesitamos [preprocesar los datos](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/features.html)\n",
    "\n",
    "En este caso normalizaremos los datos numéricos y convertiremos a one-hot los datos categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "features = StandardScaler().fit_transform(df.select_dtypes(include=[np.number]).values)\n",
    "type_one_hot = OneHotEncoder(sparse=False).fit_transform(df[\"Type\"].values.reshape(-1,1))\n",
    "features = np.concatenate((features, type_one_hot), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego convertimos la etiqueta en un valor numérico (categórico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['Failure Type'])\n",
    "np.unique(label, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el problema agruparemos las clases de falla en tan sólo una clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binary = np.zeros_like(label)\n",
    "label_binary[label==1] = 1\n",
    "np.unique(label_binary, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos una partición de test para evaluar el desempeño de nuestro clasificador. Es importante hacerlo de forma estratificada por clase para asegurar de tener ejemplos de la clase minoritaria en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label_binary, \n",
    "                                                    stratify=label_binary, test_size=0.3, random_state=12345)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe muchos modelos de machine learning para hacer clasificación, como por ejemplo el [regresor logístico](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/logistic.html), la [máquina de soporte vectorial](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/svm.html) y los [árboles de decisión](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/trees.html). Lo más correcto sería probar los distintos modelos y mantener el que obtenga mejor desempeño en test.\n",
    "\n",
    "Sin embargo, para simplificar, nos concentraremos en modelos de tipo [ensamble paralelo de árboles de decisión](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/ensembles1.html) que suelen tener buen desempeño con datos tabulares. \n",
    "\n",
    "Se realiza una [validación cruzada](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/validation.html) estratificada para escoger los hiperparámetros del modelo, a modo de ejemplo se exploran distintos valores para \n",
    "\n",
    "- la cantidad de árboles: `n_estimators`\n",
    "- el criterio utilizado para separar los nodos del los árboles: `criterion`\n",
    "\n",
    "Para combatir el desbalance de clases tomamos dos precauciones\n",
    "\n",
    "- Se utiliza ponderación para \"aumentar la importancia\" de la clase minoritaria\n",
    "- Se utiliza una métrica robusta al desbalance para hacer la validación cruzada: área bajo la curva ROC\n",
    "\n",
    "Otras opción más avanzada sería hacer [aumentación sintética de la clase minoritaria](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', max_depth=None, random_state=12345)\n",
    "params = {'n_estimators': [10, 20, 50, 100], 'criterion': ['gini', 'entropy']}\n",
    "validator = GridSearchCV(model, params, cv=5, n_jobs=4, scoring='f1')\n",
    "validator.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(validator.cv_results_).sort_values(by=\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos el desempeño del clasificador en el conjunto de test\n",
    "\n",
    "En problemas de dos clases podemos evaluar graficamente utilizando curvas de [curva de desempeño](https://phuijse.github.io/MachineLearningBook/contents/supervised_learning/metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "best_rf = validator.best_estimator_\n",
    "y_probs = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4), tight_layout=True)\n",
    "prec, rec, th = precision_recall_curve(y_test, y_probs)\n",
    "ax[0].plot(rec, prec)\n",
    "ax[0].set_xlabel('Recall')\n",
    "ax[0].set_ylabel('Precision')\n",
    "\n",
    "f1_score = (prec[:-1]*rec[:-1])/(prec[:-1] + rec[:-1])\n",
    "ax[1].plot(th, f1_score)\n",
    "ax[1].set_xlabel('Threshold')\n",
    "ax[1].set_ylabel('F1-score')\n",
    "\n",
    "best_th = np.argmax(f1_score)\n",
    "ax[0].scatter(rec[best_th], prec[best_th], c='k')\n",
    "ax[1].axvline(th[best_th], c='k', ls='--')\n",
    "ax[1].axhline(f1_score[best_th], c='k', ls='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión asociada al umbral de operación de máximo f1-score es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "y_pred = y_probs > th[best_th]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize=None,\n",
    "                                        ax=ax, cmap='Blues', colorbar=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que podemos tomar un umbral distinto. Por ejemplo si queremos aumentar el número de fallas detectadas a costa de tener muchas falsas alarmas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "y_pred = y_probs > 0.83\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize=None,\n",
    "                                        ax=ax, cmap='Blues', colorbar=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de relevencia de los atributos\n",
    "\n",
    "Una ventaja de los ensambles paralelos es que entregan como subproducto un proxy de la releveancia de las características. \n",
    "\n",
    "La siguiente figura muestra los atributos ordenados según su relevancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = np.array(list(df.select_dtypes(include=[np.number]).columns) + ['model1', 'model2', 'model3'])\n",
    "idx =  np.argsort(best_rf.feature_importances_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "ax.barh(y=fnames[idx], width=best_rf.feature_importances_[idx], label='detectadas')\n",
    "ax.set_xlabel('Ganancia de información promedio');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de errores\n",
    "\n",
    "Una vez que tenemos un modelo que es capaz de generalizar es conveniente estudiar los errores (falsos positivos y falsos negativos)\n",
    "\n",
    "En este caso utilizaremos como umbral de operación aquel de máximo f1-score\n",
    "\n",
    "La siguiente figura muestra los ejemplos de falla detectadas (azul) y las que no fueron detectadas (naranjo). Algunas fallas parecen ser más difíciles de predecir que otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict_proba(features)[:, 1] > th[best_th]\n",
    "fallas_no_detectadas = (label_binary == 0) & (y_pred == 1)\n",
    "fallas_detectadas = (label_binary == 0) & (y_pred == 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "fallas, cantidad = np.unique(le.inverse_transform(label[fallas_detectadas]), return_counts=True)\n",
    "ax.barh(y=fallas, width=cantidad, label='detectadas')\n",
    "fallas, cantidad = np.unique(le.inverse_transform(label[fallas_no_detectadas]), return_counts=True)\n",
    "ax.barh(y=fallas, width=cantidad, label='no detectadas')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50456680fccf1c41085e05954d172de063da31b4663dbf91e3dc42a7c568c15e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
